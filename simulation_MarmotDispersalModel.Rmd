---
title: "Marmot Dispersal Model"
author: "Pierre Dupont"
date: "12/1/2020"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Marmot Dispersal Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
 
This vignette demonstrates the marmot dispersal capture-recapture model, as in
"Estimation of age and sex-specific natal dispersal patterns of Alpine marmots from capture-recapture data." (Dupont *et al*, *submitted*).
Specifically, we implement the two versions of the CR model used in the paper using nimble [@de2017programming].  


### Load Libraries 

```{r packages, message=FALSE, warning=FALSE}
library(nimble)
library(basicMCMCplots)
library(coda)
```


### Define Model Structure

Here, we define the `nimble` function to extract the residency probability and the two models.
```{r models}
getResidProb <- nimbleFunction(run = function( d = double(0),
                                               s = double(0),
                                               prob.mat = double(2)){
  ## Return type declaration
  returnType(double(0))
  
  ## Get the number of territories crossed
  dist <- trunc(d) + 1
  
  ## Get the maximum number of territories crossed in the study area
  dmax <- dim(prob.mat)[2]
  
  if(dist > dmax){
    return(0.0)               ## If distance is more than the max allowed; r = 0.0
  } else {
    return(prob.mat[s, dist]) ## If distance less than dmax, extract r from prob.matrix
  }
})

dispersalModel <- nimbleCode({
  ## ----- Demographic Process -----
  phi[1] ~ dunif(0,1)
  phi[2] ~ dunif(0,1)
  delta ~ dunif(0,1)     
  h ~ dunif(0,1)  
  omega0[1:4] ~ ddirch(alpha[1:4])
  
  ## Define state-transition and observation matrices
  for (i in 1:n.individuals){
    r[i] <- getResidProb( d = d[i],
                          s = site[i],
                          prob.mat = prob.mat[1:n.sites,1:dmax])
    
    ## Define probabilities of state S(t+1) given S(t)   
    omega[1,i,1] <- phi[1] * (1-delta) * (1-h) 
    omega[1,i,2] <- phi[1] * (1-delta) * h
    omega[1,i,3] <- phi[1] * delta * r[i]
    omega[1,i,4] <- 1-phi[1] + phi[1] * delta * (1-r[i]) 
    omega[2,i,1] <- 0
    omega[2,i,2] <- phi[2]
    omega[2,i,3] <- 0
    omega[2,i,4] <- (1-phi[2]) 
    omega[3,i,1] <- 0
    omega[3,i,2] <- 0
    omega[3,i,3] <- phi[2]
    omega[3,i,4] <- (1-phi[2])
    omega[4,i,1] <- 0
    omega[4,i,2] <- 0
    omega[4,i,3] <- 0
    omega[4,i,4] <- 1
    
    ## Likelihood 
    z[i,1] ~ dcat(omega0[1:4])
    for (t in 2:n.years){
      z[i,t] ~ dcat(omega[z[i,t-1],i,1:4])
    }#t 
  }#i 
  
  
  ## ----- Spatial Process -----
  tau ~ dgamma(0.1,0.1) 
  
  for(i in 1:n.individuals){
    d[i] ~ dpois(tau)
  }#i
  
  ## ----- Detection Process -----
  p[1] ~ dunif(0,1)
  p[2] ~ dunif(0,1)
  
  ## Define probabilities of O(t) given S(t)
  theta[1,1:4] <- c(p[1], 0   , 0   , 1-p[1])
  theta[2,1:4] <- c(0   , p[2], 0   , 1-p[2])
  theta[3,1:4] <- c(0   , 0   , p[2], 1-p[2])
  theta[4,1:4] <- c(0   , 0   , 0   , 1     )

  ## Likelihood 
  for (i in 1:n.individuals){
    for (t in 2:n.years){
      y[i,t] ~ dcat(theta[z[i,t], 1:4])
    }#t 
  }#i 
})

apparentModel <- nimbleCode({
  ## ----- Demographic Process -----
  phi[1] ~ dunif(0,1)
  phi[2] ~ dunif(0,1)
  delta ~ dunif(0,1)     
  h ~ dunif(0,1)  
  omega1[1:4] ~ ddirch(alpha[1:4])
  
  ## Define state-transition and observation matrices
  for (i in 1:n.individuals){
    ## Define probabilities of state S(t+1) given S(t)   
    omega[1,i,1] <- phi[1] * (1-delta) * (1-h) 
    omega[1,i,2] <- phi[1] * (1-delta) * h
    omega[1,i,3] <- phi[1] * delta 
    omega[1,i,4] <- 1-phi[1] 
    omega[2,i,1] <- 0
    omega[2,i,2] <- phi[2]
    omega[2,i,3] <- 0
    omega[2,i,4] <- (1-phi[2]) 
    omega[3,i,1] <- 0
    omega[3,i,2] <- 0
    omega[3,i,3] <- phi[2]
    omega[3,i,4] <- (1-phi[2])
    omega[4,i,1] <- 0
    omega[4,i,2] <- 0
    omega[4,i,3] <- 0
    omega[4,i,4] <- 1
    
    ## Likelihood 
    z[i,f[i]] ~ dcat(omega0[1:4])
    for (t in (f[i]+1):n.years){
      z[i,t] ~ dcat(omega[z[i,t-1],i,1:4])
    }#t 
  }#i 
  
  ## ----- Detection Process -----
  p[1] ~ dunif(0,1)
  p[2] ~ dunif(0,1)
  
  ## Define probabilities of O(t) given S(t)
  theta[1,1:4] <- c(p[1], 0   , 0   , 1-p[1])
  theta[2,1:4] <- c(0   , p[2], 0   , 1-p[2])
  theta[3,1:4] <- c(0   , 0   , p[2], 1-p[2])
  theta[4,1:4] <- c(0   , 0   , 0   , 1     )

  ## Likelihood 
  for (i in 1:n.individuals){
    for (t in (f[i]+1):n.years){
      y[i,t] ~ dcat(theta[z[i,t], 1:4])
    }#t 
  }#i 
})
```


### Simulate Data

Here, we simulate a capture-recapture dataset that follows the  `dispersalModel` structure above with the following parameter values
```{r sim parms}
## General parameters
n.years <- 20					             ## Number of capture occasions
marked <- 500 # rep(20, n.years-1) ## Numbers of new individuals captured each year
n.individuals <- sum(marked)			 ## Total number of individuals captured
f <- rep(1:length(marked), marked) ## Vector of first capture occasions

## CMR parameters
tau <- 2.5                          ## mean dispersal distance
phi <- c(0.85,0.95)                ## survival probabilities
h <- 0.12					                 ## inheritance probability
delta <- 0.4					             ## dispersal probability of dispersers
p <- c(0.96,0.64)			             ## recapture probability
```

We start by generating a study area map by randomly selecting 35 out of 60 possible sites and calculating the residency probabilities $r$ for each site.
```{r study area}
n.sites <- 35		                              ## Number of territories
max.x <- 10			                              ## Size of the study area along x coordinates
max.y <- 6		                                ## Size of the study area along y coordinates
site.index <- sample(max.x*max.y, n.sites) 		## Random sample of territories coordinates
site.index <- site.index[order(site.index)]
studyArea.map <- matrix(0, max.y, max.x)
studyArea.map[site.index] <- 1:n.sites

dmax <- max(dim(studyArea.map))		            ## Maximum distance in the study area						
pos <- as.data.frame(which(studyArea.map != 0, arr.ind = TRUE))
X <- pos[,1]+dmax+1
Y <- pos[,2]+dmax+1
grid.mat <- matrix(NA,max(X)+dmax+1,max(Y)+dmax+1)
for (i in 1:n.sites){
  grid.mat[X[i],Y[i]] <- i
}
image(grid.mat)

prob.mat <- matrix(NA, n.sites, dmax)
for (s in 1:n.sites){
  for (d in 1:dmax){
    Xmax <- which(!is.na(grid.mat[X[s]+d,(Y[s]-d):(Y[s]+d-1)]))
    Xmin <- which(!is.na(grid.mat[X[s]-d,(Y[s]-d+1):(Y[s]+d)]))
    Ymax <- which(!is.na(grid.mat[(X[s]-d+1):(X[s]+d),Y[s]+d]))
    Ymin <- which(!is.na(grid.mat[(X[s]-d):(X[s]+d-1),Y[s]-d]))
    around <-c(Xmax,Xmin,Ymax,Ymin)	
    prob.mat[s,d] <- length(around)/(8*d)
  }
}
hist(prob.mat)
```

Then, we randomly assign individuals to a site, sample their dispersal distance and extract the corresponding individual-specific residency probabilities. (Note that these probabilities are only used for individuals that actually disperse)
```{r dispersal}
territories <- sample(x = n.sites, size = n.individuals, replace = T) 
distances <- rpois(n = n.individuals, lambda = tau) + 1	
r <- NULL   
for (i in 1:n.individuals){
  r[i] <- ifelse(distances[i]<= dim(prob.mat)[2], prob.mat[territories[i],distances[i]], 0) 		
  }#i
```

Then, we simulate individual states and capture histories
```{r CR data}
# 1. Ecological process matrix
OMEGA <- array(NA, dim = c(4, 4, n.individuals))			
for (i in 1:n.individuals){
  OMEGA[,,i] <- matrix(c(
    phi[1]*(1-delta)*(1-h), phi[1]*(1-delta)*h , phi[1]*delta*r[i]  , 1-phi[1]+phi[1]*delta*(1-r[i]) ,
    0               , phi[2]         , 0            , 1-phi[2]         , 
    0               , 0            , phi[2]         , 1-phi[2]         ,
    0               , 0            , 0            , 1               
  ), nrow = 4, byrow = TRUE)
}

# 2.Observation process matrix
THETA <- matrix(c(
  p[1] , 0   , 0   ,(1-p[1]),
  0  , p[2]  , 0   ,(1-p[2]),
  0  , 0   , p[2]  ,(1-p[2]),		
  0  , 0   , 0   , 1                                
), nrow = 4, byrow = TRUE)

# 3.Sample annual individual states and observations
y <- z <- matrix(NA, nrow = n.individuals, ncol = n.years)
for (i in 1:n.individuals){
  y[i,f[i]] <- z[i,f[i]] <- 1
  if (f[i] == n.years) next
  for (t in (f[i]+1):n.years){
    z[i,t] <- rcat(n = 1, prob = OMEGA[z[i,t-1],1:4,i])
    y[i,t] <- rcat( n= 1, prob = THETA[z[i,t],1:4])													
  }#t 
}#i
    
d.observed <- rep(NA, n.individuals)									 
d.observed[which(y == 3, arr.ind = TRUE)[ ,1]] <- distances[which(y == 3, arr.ind = TRUE)[ ,1]]
```


Then, we organize the simulated data in a format useable by NIMBLE; i.e. we create objects `constants`, `data`, and `inits` for later use in the function `nimbleModel`. 
```{r NIMBLE data}
nimData <- list( y = y,
                 alpha = rep(1,4),
                 prob.mat = prob.mat,
                 # f = f,
                 site = territories,
                 d = d.observed-1)

nimConstants <- list(n.individuals = dim(y)[1],
                     n.years = dim(y)[2],
                     n.sites = dim(prob.mat)[1],
                     dmax = dim(prob.mat)[2])
dist.inits <- rpois(n.individuals, 3)
dist.inits[!is.na(nimData$d)] <- NA
nimInits <- list(z = z,
                 tau = 3,
                 p = c(0.5,0.9),
                 phi = c(0.7,0.9),
                 d= dist.inits,
                 delta = 0.25,
                 h = 0.15)
```


## Create NIMBLE model object

Now, we can create the `nimble` model object, using the model structure
defined in `code`, and the constants, data, and initial values.
```{r NIMBLE Rmodel}
Rmodel <- nimbleModel( code = dispersalModel,
                       constants = nimConstants,
                       data = nimData,
                       inits = nimInits)
```


#### Configure and Build MCMC

We configure an MCMC algorithm to the `Rmodel` model object.

We assign MCMC monitors to $\phi$, $\delta$, $h$, $\tau$, and $p$.

```{r NIMBLE config, message=FALSE}
conf <- configureMCMC(Rmodel, monitors = c("phi", "p", "tau", "h", "delta"), print = FALSE)
Rmcmc <- buildMCMC(conf)
```


#### Compile and Run MCMC

Finally, we compile both the model and MCMC objects and
execute the compiled MCMC for 10 000 iterations.

```{r NIMBLE compile}
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
MCMC_runtime <- system.time(
  samples <- runMCMC(Cmcmc, niter = 5000, nchains = 3, samplesAsCodaMCMC = T)
)
```

## Results

First, we can extract the MCMC runtime (`r round(MCMC_runtime[3] / 60, 1)` minutes in this case): 
```{r }
round(MCMC_runtime[3] / 60, 1)
```

Next, we can check the posterior effective sample size (ESS) resulting from our
10 000 posterior samples for the three parameters we tracked ($N$, $\sigma$, and $p_0$):  
```{r }
round(effectiveSize(samples),2) 
```

We can also calculate the MCMC efficiency for each parameter; this corresponds to the rate of generating effectively independent posterior samples, per second of MCMC runtime:
```{r }
 round(effectiveSize(samples)/MCMC_runtime[3],2)  
```

Summary of posterior distributions for each parameter:
```{r }
summary(samples)
```

Examine traceplots and posterior distributions:
```{r , fig.width=10, fig.height=10}
basicMCMCplots::chainsPlot(samples)
```
